# Введение. Основные понятия.
## Применение
> `FX` - т.е. "вызвать функцию _F_ с параметром _X_".  

_X_ тоже может быть функцией, даже самой _F_: `FF`

## Абстракция
> `λx.M` - означает `x ↦ M(x)`.  

**ПРИМЕР 1:** `λx.2*x` - функция, кот. возвращает удвоенный аргумент.  
**ПРИМЕР 2:** `λx.2` - константная функция, кот. всегда возвращает 2.  

## Множество λ-термов
Множество λ-термов **Λ** строится из:
 1. Переменных `{x, y, z...} ∈ V`
 2. Применения
 3. Абстракции

```
x ∈ V => x ∈ Λ
M,N ∈ Λ => MN ∈ Λ
M ∈ Λ, x ∈ V => λx.M ∈ Λ
```

**ПРИМЕРЫ λ-ТЕРМОВ:**  

| Со скобками  | То же самое без скобок |
| :-------------: | :-------------: |
| x  | x  |
| (xz)  | xz  |
| (λx.(xz)) | λx.xz |
| (λx.(xz))y | (λx.xz)y |
| λy.(λx.(xz))y | λy.(λx.xz)y |

## Правила опускания скобок
`FXYZ` = `((FX)Y)Z` - 'ассоциативно влево'  
`λxyz.M` = `λx.(λy.(λz.M))` - 'ассоциативно вправо'  
`λx.MNK` = `λx.(MNK)` - вправо насколько возможно  

## α-преобразование (переименование)
> Переименование аргумента, чтобы не наебаться когда подставляем какие-то значения.
Так можно делать только со связанными переменными!  
`λx.M =α λy.M, y ∉ FV(M)`

**ПРИМЕР**: `λy.xy[x:=y] = λy'.xy'[x:=y] = λy'.yy'`  

## β-преобразование (подстановка)
> Подстановка аргумента в функцию называется **β-эквиваленость**.  
`(λx.M)N =β M[x:=N]`, т.е. в терме _M_ мы каждое вхождение _x_ заменяем на _N_.  

**ПРИМЕР:** `(λx.2x+8)17 =β 2*17+8 = 42`

## η-преобразование
> `λx.Mx = M, x ∈ FV(M)`

## Редекс
> Конструкция вида `(λx.M)N` называется **РЕДЕКС** (т.е. мы можем сразу β-подставить)  

## Определение равенства функций
> **Экстенсионально эквивалентные** - те функции, кот. при одинаковом входе дадут одинаковый результат.  

```
∀x : Fx = Gx

Ниже - определение равенства функций
y ∉ FV(F) ∪ FV(G)
Fy = Gy
λy.Fy = λy.Gy
F = G
```

## Свободные и связанные переменные
> `λx.M[x]` - наличие _x_ в теле функции (_x_ при этом аргумент) **связывает** до этого **свободную** _x_.  

**ПРИМЕР 1:** `(λy.(λx.xz)y)w`: _x_, _y_ - связанные, _z_, _w_ - свободные.  
**ПРИМЕР 2:** `(λx.(λx.xz)x)x`: нам только кажется, что здесь полно одинаковых _x_.  
На самом деле это выглядит так: `(λx1.(λx2.x2z)x1)x3`, _x1_, _x2_, _x3_ - **разные _x_**!  
_x1_ и _x2_ - связанные, _x3_ и _z_ - свободные.  

**Связанная переменная полностью описана внутри функции** и про внешний мир ей ничего знать не надо.  
**Свободная переменная глобальна относительно данной функции.**  

> Формально:  
>
Свободные **FV(T)**:
 * FV(x) = {x}
 * FV(MN) = FV(M) ∪ FV(N)
 * FV(λx.M) = FV(M) \ {x}  
>
Связанные **BV(T)**:
 * BV(x) = ∅
 * BV(MN) = BV(M) ∪ BV(N)
 * BV(λx.M) = BV(M) ∪ {x}

## Комбинаторы
> **Комбинатор** - замкнутый (без свободных переменных) терм.  

Некоторые классические комбинаторы:  
 * `1` = `λxy.xy`
 * `I` = `λx.x`
 * `ω` = `λx.xx`
 * `Ω` = `ωω` = `(λx.xx)(λx.xx)`
 * `K` = `λxy.x`
 * `K*` = `λxy.y`
 * `B` = `λfgx.f(gx)`
 * `S` = `λfgx.fx(gx)`

## Каррирование
> **Каррирование** - переход от функции нескольких переменных к последовательным функциям одной переменной.  

Как это делается (в этом примере _Φx_ - это один терм, _x_ - как бы подстрочный):  
Есть `φ(x,y)`, тогда `Φx = λy.φ(x,y)`. `Φ = λx.Φx = λxy.φ(x,y)`  
`ΦXY = (ΦX)Y = ΦxY = (λy.φ(X,y))Y = φ(X,Y)`.

# Аксиомы
 1. `M = M`
 2. `M = N => N = M`
 3. `M = N, N = L => M = L`
 4. `M = M' => MZ = M'Z`
 5. `M = M' => ZM = ZM'`
 6. `M = M' => λx.M = λx.M'`

# Рекурсия

## Теорема о неподвижной точке
`∀F∈Λ ∃X∈Λ | λ ↦ FX=X`  
Док-во:  
Обозначим `W = λx.F(xx)`, `X = WW`  
Тогда `X = WW = (λx.F(xx))W = F(WW) = FX`  
`W` и есть искомая точка.  

## Теорема об Y-комбинаторе
**F(YF) = YF**  
(работает и в обратную сторону)  

∃ комбинатор Y неподвижной точки такой, что `∀F F(YF) = YF`  
`YF = (λx.F(xx))(λx.F(xx))`

Y-комбинатор позволяет ввести рекурсию.  
**ПРИМЕР:** Факториал:  
`fac = λn.iif(iszro n)1(mult n (fac(pred n)))` =>  
`fac = (λfn.iif(iszro n)1(mult n (f(pred n)))) fac` все выражение в скобках обозначим `fac'`
`fac = Y fac'`

Посчитаем для примера факториал трех:
```
fac 3 = (Y fac')3 = fac'(Y fac')3 = 
iif(iszro 3)1(mult 3 (Y fac'(pred 3))) =
mult 3 ((Y fac') (pred 3)) = 
mult 3 (fac' (Y fac') 2) = 
mult 3 (mult 2 (fac' (Y fac') 1)) = 
mult 3 (mult 2 (mult 1 (fac' (Y fac') 0))) = 
mult 3 (mult 2 (mult 1 1))) = 6
```

## Редукция термов
```
KI ≡ (λxy.x)(λz.z) = λyz.z
IIK* ≡ (λx.x)IK* = IK* = (λx.x)(λyz.z) = λyz.z
```
Видно, что процесс носит односторонний характер, термы "упрощаются". Для этого вводят понятие **редукции**:  
Несколько видов стрелочек:
 * `KI →β K*` - редуцируется за один шаг,  
 * `IIK* ↠β K*` - редуцируется за [0, n] шагов,  
 * `KI =β IIK*` - конвертируемо (равно)  

> Терм вида `(λx.M)N` наз. **β-редексом** (или просто редексом).  

> Терм `M[x:=N]` называется **сокращением** редекса `(λx.M)N`

**ПРИМЕР:**
`I(KI)` содержит два редекса:  
`(λx.x)((λyz.y)(λp.p))`  

### Понятие редукции
> Бинарное отношение _R_ над Λ наз. **совместимым** (с операциями λ-исчисления),
> если для любых M,N,Z ∈ Λ:
> M _R_ N ⇒ (ZM) _R_ (ZN),
>   (MZ) _R_ (NZ),
>   (λx.M) _R_ (λx.N)

> Совместимое отношение эквивалентности наз. отношением **конгруэнтности** над Λ.

> Совместимое, рефлексивное и транзитивное отношение наз. отношением **редукции** над Λ.

**ПРИМЕР:**
Возвращаясь к предыдущему примеру, развернем редексы сначала первый потом второй и наоборот:  
`(λx.x)((λyz.y)(λp.p)) →β (λy.zy)(λp.p) →β λzp.p`  
`(λx.x)((λyz.y)(λp.p)) →β (λx.x)(λzp.p) →β λzp.p`  

> **определение**: Бинарное отношение β-редукции ↠β над λ (индуктивно):  
>   (a) M ↠β M  
>   (b) M →β N ⇒ M ↠β N  
>   (c) M ↠β N, N ↠β L ⇒ M ↠β L  

### Отношение конвертируемости =β
> **определение**: Бинарное отношение =β над Λ (индуктивно):  
>   (a) M ↠β N ⇒ M =b N  
>   (b) M =β N ⇒ N =b M  
>   (c) M =β N, N =β L ⇒ M =β L  

Отношение `=β` является отношением конгруэнтности.  
Работает во все стороны (правило (с)): `KI →β K* ←β IK* ←β IIK*` => `KI =b IIK*`

### Нормальная форма
Официально - β-нормальная форма.  
> λ-терм М **находится** в β-нормальной форме (β-NF), если в нем нет подтермов, являющихся β-редексами.

> λ-терм М **имеет** β-нормальную форму, если для некоторого N выполняется M =β N и N находится в β-NF

**Не все термы имеют β-норм форму**.
**ПРИМЕР:** - `Ω = ωω = (λx.xx)(λx.xx) ↠β (λx.xx)(λx.xx) ...`  
Но это еще не доказательство! Может быть, есть такой N, что Ω <<- M ->> N  

Не все последовательности редукций приводят к нормальной форме!  
Пример - `K I Ω` - если наччать с раскрытия Ω, то получится бесконечная редукция.  

Редукцию можно изображать с помощью _редукционного графа_, может быть бесконечен.  
Не все бесконечные не имеют НФ. Если у терма есть НФ - то мы всегда можем к ней перейти.  

## Теорема Чёрча-Россера
*Конфлюэнтность* - если из `M` мы можем перейти к `N` или `K`,
то из них обоих мы можем перейти в какой-ниб `L` (иллюстрация - ромб).  

### Следствия
 1. Если `M =β N`, то у них существует **общий редукт** `L`.  
 2. Если `M` имеет `N` в качестве _β-NF_, то `M` редуцируется к `N` (можем доказать отсутствие NF)  
 3. любой λ-терм имеет не более одной НФ (можем доказать неравенство на основании неравенства НФ термов).  

## Стратегии редукции
 1. Переменная `v` - редукция завершена
 2. Абстракция `λx.M` - редуцируем `M`
 3. Аппликация `MN`:
 4. Разбираем влево: `A B → A1 A2 B → A11 A12 A2 B ...` пока слева не будет переменная или λ.
 5. Если слева стоит λ, то:
 6. Нормальная стратегия: сокращаем редекс `(λx.M)N`
 7. Аппликативная стратегия: сначала сокращаем аргументы функции, потом - саму функцию.

λ-термы представляют в виде **синтаксических деревьев**.

### Головная форма
`λx1 ... xn.y N1 ... Nk, n ≥ 0, k ≥ 0` - головная нормальная форма.  
`λx1 ... xn.(λy.Z) N1 ... Nk, n ≥ 0, k > 0` - λy.Z - головной редекс  
Слабая ГНФ - не-редекс на верхнем уровне. В языках программирования на ней чаще всего останавливается вычисление.  

### Нормальная стратегия:
`NF` - норм. форма: `NF ::== λx.NF | NANF`  
`NANF` - не абстракция: `NANF ::== v | NANF NF`  
`NA` - не абстракция: `NA ::== v | PQ`  
 1. Если `NA → NA'`, то `NA M → NA' M`
 2. Если `M → M'`, то `NA N → NA M'`
 3. Если `M → M'`, то `λx.M → λx.M'`
 4. `(λx.M)N` → `M[x:=N]`

Нормальная стратегия всегда сокращает самый левый внешний редекс.  
**Нормальная стратегия гарантированно приведет к НФ**.  
Ее недостаток - иногда неэффективна: `(λx.Fx(Gx))N → FN(GN)`. `N` придется вычислять дважды (а вдруг он большой и тяжелый).  
А иногда - наоборот, может пропустить тяжелое вычисление: `(λxy.y)N → λy.y`  
Аппликативная стратегия в обоих примерах вычислит `N` один раз.  
Т.е. если какие-то вычисления нужны много раз - нормальная стратегия проигрывает.  

### Аппликативная стратегия:
Как нормальная, но:  
_4. `(λx.M)NF` → `M[x:=NF]`  
_5. Если `N → N'`, то `(λx.M)N → (λx.M)N'`  
Аппликативная стратегия всегда сокращает самый левый внутренний редекс.

# Булевы значения
```
tru = λtf.t //истина
fls = λtf.f //ложь
iif = λbxy.bxy //если

not = λb.b fls tru //не
and = λxy.xy fls //конъюнкция
```
